# ai_flipchart_streamlit_whisper_api.py
"""
Streamlit web-app: mikrofon â†’ OpenAI Whisper â†’ Make webhook â†’ Å¾ivÃ½ Flipchart
---------------------------------------------------------------------------

Co dÄ›lÃ¡
-------
â€¢ Å½ivÃ½ mikrofon i testovacÃ­ upload souboru (WAV/MP3/M4A)  
â€¢ OpenAI Whisper â†’ text pÅ™episu  
â€¢ PÅ™epis + stÃ¡vajÃ­cÃ­ body odeÅ¡le na Make webhook  
  (https://hook.eu2.make.com/k08ew9w6ozdfougyjg917nzkypgq24f7)  
  âœ ScÃ©nÃ¡Å™ v Make vrÃ¡tÃ­ **JSON pole novÃ½ch odrÃ¡Å¾ek**  
â€¢ Ty se animovanÄ› doplnÃ­ na Flipchart  
â€¢ DiagnostickÃ© okno se stavem zpracovÃ¡nÃ­, robustnÃ­ zachytÃ¡vÃ¡nÃ­ chyb  
â€¢ VlÃ¡kno audio-pipeline se korektnÄ› restartuje pÅ™i kaÅ¾dÃ©m rerunu
"""

from __future__ import annotations

import asyncio
import contextlib
import io
import json
import logging
import threading
import wave
from typing import List

import numpy as np
import requests
import streamlit as st
from openai import OpenAI, OpenAIError
from streamlit_webrtc import WebRtcMode, webrtc_streamer
from streamlit.runtime.scriptrunner import add_script_run_ctx

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("ChybÃ­ OPENAI_API_KEY â€“ pÅ™idejte jej do Secrets / env vars")
    st.stop()

MAKE_WEBHOOK_URL = (
    "https://hook.eu2.make.com/k08ew9w6ozdfougyjg917nzkypgq24f7"
)  # <- zde zmÄ›Åˆ, pokud bude jinÃ½

client = OpenAI(api_key=OPENAI_API_KEY)
AUDIO_BATCH_SECONDS = 160  # kolik sekund audia poÅ¡leme v jednÃ© dÃ¡vce do Whisperu

logging.basicConfig(level=logging.INFO)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SESSION STATE INIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "flip_points" not in st.session_state:
    st.session_state.flip_points: List[str] = []
if "transcript_buffer" not in st.session_state:
    st.session_state.transcript_buffer = ""
if "audio_buffer" not in st.session_state:
    st.session_state.audio_buffer: list[bytes] = []
if "status" not in st.session_state:
    st.session_state.status = "ğŸŸ¡ ÄŒekÃ¡m na mikrofonâ€¦"
if "upload_processed" not in st.session_state:
    st.session_state.upload_processed = False
# vlÃ¡kno + stop_event pro pipeline
if "audio_stop_event" not in st.session_state:
    st.session_state.audio_stop_event: threading.Event | None = None
if "runner_thread" not in st.session_state:
    st.session_state.runner_thread: threading.Thread | None = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STATUS HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def set_status(s: str) -> None:
    if st.session_state.status != s:
        st.session_state.status = s

@contextlib.contextmanager
def status_ctx(running: str, done: str | None = None):
    prev = st.session_state.status
    set_status(running)
    try:
        yield
    finally:
        set_status(done or prev)

def whisper_safe(file_like, label: str) -> str | None:
    """VolÃ¡ Whisper; pÅ™i chybÄ› zaloguje, zobrazÃ­ a vrÃ¡tÃ­ None."""
    try:
        return (
            client.audio.transcriptions.create(
                model="whisper-1", file=file_like, language="cs"
            ).text
        )
    except OpenAIError as e:
        logging.exception("Whisper API error (%s)", label)
        set_status(f"âŒ Chyba Whisperu ({label})")
        st.error(
            "âŒ Whisper API vrÃ¡tilo chybu â€“ zkontroluj formÃ¡t/velikost souboru "
            "a kredit ÃºÄtu.\n\n"
            f"Typ chyby: **{e.__class__.__name__}**"
        )
        return None

def call_make_webhook(transcript: str, existing: list[str]) -> list[str]:
    """PoÅ¡le JSON na Make, vrÃ¡tÃ­ list novÃ½ch bodÅ¯ (nebo prÃ¡zdnÃ½)."""
    payload = {"transcript": transcript, "existing": existing}
    try:
        r = requests.post(MAKE_WEBHOOK_URL, json=payload, timeout=60)
        r.raise_for_status()
        data = r.json()
        if not isinstance(data, list):
            logging.error("Webhook nevrÃ¡til list: %s", data)
            set_status("âš ï¸ NeplatnÃ¡ odpovÄ›Ä webhooku")
            return []
        return [str(p).strip() for p in data if str(p).strip()]
    except Exception as e:
        logging.exception("Chyba pÅ™i volÃ¡nÃ­ Make webhooku")
        set_status("âŒ Chyba webhooku")
        st.error(f"âŒ Chyba pÅ™i volÃ¡nÃ­ Make scÃ©nÃ¡Å™e: {e}")
        return []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STYLES = """
<style>
ul.flipchart {list-style-type:none; padding-left:0;}
ul.flipchart li {opacity:0; transform:translateY(8px); animation:fadeIn 0.45s forwards;}
@keyframes fadeIn {to {opacity:1; transform:translateY(0);}}
.fullscreen header, .fullscreen #MainMenu, .fullscreen footer {visibility:hidden;}
.fullscreen .block-container {padding-top:0.5rem;}
</style>
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_flipchart() -> None:
    st.markdown(STYLES, unsafe_allow_html=True)
    pts = st.session_state.flip_points
    if not pts:
        st.info("ÄŒekÃ¡m na prvnÃ­ shrnutÃ­â€¦")
        return
    st.markdown(
        "<ul class='flipchart'>" +
        "".join(
            f"<li style='animation-delay:{i*0.1}s'>{p}</li>"
            for i, p in enumerate(pts)
        ) +
        "</ul>",
        unsafe_allow_html=True,
    )

def pcm_frames_to_wav(frames: list[bytes], sr: int = 48000) -> bytes:
    if not frames:
        return b""
    pcm = np.frombuffer(b"".join(frames), dtype=np.int16)
    with io.BytesIO() as buf:
        with wave.open(buf, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sr)
            wf.writeframes(pcm.tobytes())
        buf.seek(0)
        return buf.read()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI LAYOUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="AI Flipchart", layout="wide")
tabs = st.tabs(["ğŸ›  OvlÃ¡dÃ¡nÃ­", "ğŸ“ Flipchart"])

# ========== TAB 1: OvlÃ¡dÃ¡nÃ­ ================================================
with tabs[0]:
    st.header("NastavenÃ­ a vstup zvuku")

    # â€”â€” TESTOVACÃ UPLOAD â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    uploaded = st.file_uploader(
        "â–¶ï¸ Nahrajte WAV/MP3 k otestovÃ¡nÃ­ (max pÃ¡r minut)",
        type=["wav", "mp3", "m4a"],
        accept_multiple_files=False,
    )
    if uploaded is not None and not st.session_state.upload_processed:
        with status_ctx("ğŸŸ£ OdesÃ­lÃ¡m soubor do Whisperâ€¦"):
            st.info("â³ ZpracovÃ¡vÃ¡m nahranÃ½ souborâ€¦")
            transcription = whisper_safe(uploaded, label="upload")
            if transcription:
                with status_ctx("ğŸ§  VolÃ¡m Make webhookâ€¦"):
                    new_pts = call_make_webhook(
                        transcript=transcription,
                        existing=st.session_state.flip_points,
                    )
                    st.session_state.flip_points.extend(new_pts)
                st.success("âœ… Soubor zpracovÃ¡n â€“ pÅ™epnÄ›te na zÃ¡loÅ¾ku Flipchart")
                st.session_state.upload_processed = True

    # â€”â€” Å½IVÃ MIKROFON â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    st.subheader("ğŸ¤ Å½ivÃ½ mikrofon")
    webrtc_ctx = webrtc_streamer(
        key="workshop-audio",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"audio": True, "video": False},
    )

    # â€” zastav pÅ™edchozÃ­ vlÃ¡kno (pÅ™i rerunu) â€”
    old_t = st.session_state.runner_thread
    if old_t and old_t.is_alive():
        st.session_state.audio_stop_event.set()
        old_t.join(timeout=2)

    stop_evt = threading.Event()
    st.session_state.audio_stop_event = stop_evt

    async def pipeline_runner(ctx, stop_event: threading.Event):
        SAMPLE_RATE = 48000
        bytes_per_sec = SAMPLE_RATE * 2
        target = AUDIO_BATCH_SECONDS * bytes_per_sec

        while not stop_event.is_set():
            if not ctx.audio_receiver:
                set_status("ğŸŸ¡ ÄŒekÃ¡m na mikrofonâ€¦")
                await asyncio.sleep(0.1)
                continue

            set_status("ğŸ”´ ZachytÃ¡vÃ¡m audioâ€¦")
            frames = await ctx.audio_receiver.get_frames(timeout=1)
            st.session_state.audio_buffer.extend(
                fr.to_ndarray().tobytes() for fr in frames
            )
            if sum(len(b) for b in st.session_state.audio_buffer) < target:
                await asyncio.sleep(0.05)
                continue

            wav_bytes = pcm_frames_to_wav(st.session_state.audio_buffer)
            st.session_state.audio_buffer.clear()

            set_status("ğŸŸ£ OdesÃ­lÃ¡m do Whisperâ€¦")
            transcription = whisper_safe(io.BytesIO(wav_bytes), label="mikrofon")
            if not transcription:
                await asyncio.sleep(1)
                continue

            st.session_state.transcript_buffer += " " + transcription

            if len(st.session_state.transcript_buffer.split()) >= 325:
                set_status("ğŸ§  VolÃ¡m Make webhookâ€¦")
                new_pts = call_make_webhook(
                    transcript=st.session_state.transcript_buffer,
                    existing=st.session_state.flip_points,
                )
                st.session_state.flip_points.extend(
                    [p for p in new_pts if p not in st.session_state.flip_points]
                )
                st.session_state.transcript_buffer = ""

            set_status("ğŸŸ¢ ÄŒekÃ¡m na dalÅ¡Ã­ dÃ¡vkuâ€¦")
            await asyncio.sleep(0.05)

        set_status("â¹ï¸ Audio vlÃ¡kno ukonÄeno")

    t = threading.Thread(
        target=lambda c=webrtc_ctx, e=stop_evt: asyncio.run(pipeline_runner(c, e)),
        daemon=True,
        name="audio-runner",
    )
    add_script_run_ctx(t)
    t.start()
    st.session_state.runner_thread = t

    # â€”â€” SIDEBAR DIAGNOSTIKA â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    st.sidebar.header("â„¹ï¸ Stav aplikace")
    st.sidebar.write("Body na flipchartu:", len(st.session_state.flip_points))
    st.sidebar.write("Slov v bufferu:", len(st.session_state.transcript_buffer.split()))
    st.sidebar.subheader("ğŸ§­ Stav zpracovÃ¡nÃ­")
    st.sidebar.write(st.session_state.get("status", "â” NeznÃ¡mÃ½ stav"))
    st.sidebar.write("VlÃ¡kno Å¾ije:", t.is_alive())

# ========== TAB 2: Flipchart ===============================================
with tabs[1]:
    st.components.v1.html(
        "<script>document.body.classList.add('fullscreen');</script>", height=0
    )
    render_flipchart()
