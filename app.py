# audio_upload_whisper_segmenter_live.py
"""
Streamlit aplikace: 
1) **Upload reÅ¾im** â€“ uÅ¾ivatel nahraje audio soubor â†’ segmentace FFmpeg â†’ Whisper â†’ Make â†’ bulletâ€‘points.
2) **Live reÅ¾im (WebRTC)** â€“ aplikace zachytÃ¡vÃ¡ mikrofon / virtuÃ¡lnÃ­ loopâ€‘back v prohlÃ­Å¾eÄi (streamlitâ€‘webrtc), 
   kaÅ¾dÃ½ch 60Â s odeÅ¡le buffer do Whisper â†’ Make â†’ bulletâ€‘points.

VyÅ¾aduje:
    pip install streamlit streamlit-webrtc av openai ffmpeg-python requests

Pro systÃ©movÃ½ zvuk pouÅ¾ijte virtuÃ¡lnÃ­ zaÅ™Ã­zenÃ­ (VBâ€‘Audio, BlackHole, Loopbackâ€¦)
a nastavte je jako vstupnÃ­ mikrofon vÂ prohlÃ­Å¾eÄi.
"""
from __future__ import annotations

import io
import os
import re
import shutil
import subprocess
import tempfile
import threading
import time
import wave
from pathlib import Path
from typing import List

import av  # streamlit-webrtc zÃ¡vislost
import numpy as np
import requests
import streamlit as st
from streamlit_webrtc import AudioProcessorBase, webrtc_streamer

import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NastavenÃ­ API klÃ­ÄÅ¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MAKE_URL  = st.secrets.get("make_url", "")
MAKE_TOKEN = st.secrets.get("make_token", "")

openai.api_key = OPENAI_API_KEY

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helper: PCM â†’ WAV (bytes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pcm_to_wav(pcm_bytes: bytes, sr: int = 16_000) -> bytes:
    """ZabalÃ­ raw 16â€‘bit mono PCM do WAV kontejneru (inâ€‘memory)."""
    buf = io.BytesIO()
    with wave.open(buf, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)          # 16â€‘bit
        wf.setframerate(sr)
        wf.writeframes(pcm_bytes)
    return buf.getvalue()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Whisper transkripce â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def whisper_transcribe(audio_bytes: bytes, fname: str = "audio.wav") -> str:
    """PoÅ¡le audio bytes do Whisperâ€‘1 (OpenAI) a vrÃ¡tÃ­ text."""
    try:
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = fname
        resp = openai.audio.translations.create(
            model="whisper-1",
            file=audio_file,
            response_format="text",
        )
        return resp  # type: ignore â€“ OpenAI vracÃ­ str
    except Exception as e:
        st.error(f"âŒ Whisper chyba: {e}")
        return ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Make webhook â†’ bulletâ€‘points â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def post_to_make(text: str) -> List[str]:
    """OdeÅ¡le transkript do Make webhooku a oÄekÃ¡vÃ¡ list bulletâ€‘pointÅ¯."""
    if not text.strip():
        return []
    try:
        r = requests.post(
            MAKE_URL,
            json={"token": MAKE_TOKEN, "transcript": text, "existing": []},
            timeout=90,
        )
        r.raise_for_status()
        data = r.json()
        return data if isinstance(data, list) else []
    except Exception as e:
        st.error(f"âŒ Make webhook chyba: {e}")
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FormÃ¡tovÃ¡nÃ­ bulletâ€‘pointÅ¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DASH = re.compile(r"\s+-\s+")

def fmt_bullet(raw: str) -> str:
    """Nadpis (prvnÃ­ Å™Ã¡dek) tuÄnÄ› (uppercase), podâ€‘body jako <li>â€¦</li>."""
    if "\n" in raw:
        parts = [ln.strip() for ln in raw.splitlines() if ln.strip()]
    else:
        items = DASH.split(raw.strip())
        parts = [items[0]] + [f"- {p}" for p in items[1:]]
    if not parts:
        return ""
    head, *det = parts
    head_html = f"<strong>{head.upper()}</strong>"
    if not det:
        return head_html
    det_html = "".join(f"<li>{d}</li>" for d in det)
    return f"{head_html}<ul>{det_html}</ul>"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit UI -----------------------------------------------------------------
st.set_page_config(page_title="AI moderÃ¡tor â€“ live bulletâ€‘points", page_icon="ğŸ™ï¸")

st.title("ğŸ™ï¸ AI moderÃ¡tor â€“ pÅ™epis a bulletâ€‘pointy v reÃ¡lnÃ©m Äase")

MODE = st.sidebar.radio(
    "ReÅ¾im",
    ("Live (WebRTC)", "Soubor upload"),
    index=0,
    help="Live reÅ¾im zachytÃ¡vÃ¡ mikrofon/systÃ©movÃ½ zvuk pÅ™es WebRTC. "
    "Upload reÅ¾im umoÅ¾nÃ­ nahrÃ¡t existujÃ­cÃ­ audio soubor.",
)

# Container pro dynamickÃ© bulletâ€‘pointy
bullet_placeholder = st.empty()
if "bullets" not in st.session_state:
    st.session_state["bullets"] = []

def render_bullets():
    bullets = st.session_state.get("bullets", [])
    if bullets:
        bullet_placeholder.markdown(
            "<hr><h3>ğŸ“Œ Bulletâ€‘pointy</h3><ul>"
            + "".join(f"<li>{fmt_bullet(b)}</li>" for b in bullets)
            + "</ul>",
            unsafe_allow_html=True,
        )

render_bullets()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Live reÅ¾im (WebRTC) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if MODE == "Live (WebRTC)":
    st.info(
        "ğŸ”´ **Live**: Aplikace nahrÃ¡vÃ¡ zvuk z vaÅ¡eho mikrofonu "
        "(nebo virtuÃ¡lnÃ­ho loopâ€‘backu) a kaÅ¾dou minutu ho odesÃ­lÃ¡ do Whisperu."
    )

    SEGMENT_SEC = st.sidebar.slider("Interval odesÃ­lÃ¡nÃ­ (s)", 30, 120, 60, 5)
    SAMPLE_RATE = 16_000

    class LiveAudioProcessor(AudioProcessorBase):
        def __init__(self):
            self.buffer = bytearray()
            self.last_sent = time.time()
            self.lock = threading.Lock()
            self.counter = 0

        def recv_audio(self, frame):
            pcm = frame.to_ndarray()  # int16 numpy array
            with self.lock:
                self.buffer.extend(pcm.tobytes())
                elapsed = time.time() - self.last_sent
                if elapsed >= SEGMENT_SEC:
                    pcm_bytes = bytes(self.buffer)
                    # VyprÃ¡zdnit buffer a posunout timestamp
                    self.buffer.clear()
                    self.last_sent = time.time()
                    # AsynchronnÄ› zpracovat segment
                    threading.Thread(
                        target=self._process_segment,
                        args=(pcm_bytes, self.counter),
                        daemon=True,
                    ).start()
                    self.counter += 1
            return frame  # passthrough

        def _process_segment(self, pcm_bytes: bytes, idx: int):
            wav_bytes = pcm_to_wav(pcm_bytes, sr=SAMPLE_RATE)
            transcript = whisper_transcribe(wav_bytes, fname=f"live_{idx:03d}.wav")
            bullets = post_to_make(transcript)
            if bullets:
                st.session_state.setdefault("bullets", []).extend(bullets)
                # UI refresh
                render_bullets()
                st.toast(f"ğŸ“ PÅ™idÃ¡no {len(bullets)} bulletâ€‘pointÅ¯", icon="âœ…")

    webrtc_streamer(
        key="live_audio",
        mode="SENDRECV",
        audio_processor_factory=LiveAudioProcessor,
        media_stream_constraints={"audio": True, "video": False},
        async_processing=True,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Soubor upload reÅ¾im (pÅ¯vodnÃ­ workflow) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
else:
    uploaded = st.file_uploader(
        "Nahrajte audio soubor (MP3/WAV/M4A)â€¦",
        type=["mp3", "wav", "m4a"],
        accept_multiple_files=False,
    )

    if uploaded:
        import ffmpeg  # dynamickÃ½ import â€“ jen kdyÅ¾ je potÅ™eba

        # 1) UloÅ¾it upload do temp
        raw_bytes = uploaded.read()
        size_mb = len(raw_bytes) / (1024 * 1024)
        st.write(f"Velikost nahrÃ¡vky: **{size_mb:.1f}\u00a0MB**")

        tmp_input = tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded.name).suffix)
        tmp_input.write(raw_bytes)
        tmp_input.flush()
        tmp_input_path = tmp_input.name
        tmp_input.close()

        # 2) DoÄasnÃ½ adresÃ¡Å™ pro 30Â s segmenty
        tmp_dir = tempfile.mkdtemp(prefix="audio_chunks_")

        # 3) Spustit FFmpeg segmentaci
        with st.spinner("ğŸ”€ Segmentuji pomocÃ­ FFmpegâ€¦"):
            (
                ffmpeg
                .input(tmp_input_path)
                .output(
                    str(Path(tmp_dir) / "chunk%03d.mp3"),
                    ar=16_000, ac=1, audio_bitrate="32k",
                    f="segment", segment_time=30, reset_timestamps=1,
                    loglevel="error"
                )
                .overwrite_output()
                .run()
            )

        # 4) SeÅ™adit segmenty a poslat do Whisper
        chunks = sorted(Path(tmp_dir).glob("chunk*.mp3"))
        transcripts: List[str] = []
        prog = st.progress(0, "ğŸ™ï¸ Transkribujiâ€¦")
        for i, ch in enumerate(chunks, start=1):
            with ch.open("rb") as f:
                transcripts.append(whisper_transcribe(f.read(), ch.name))
            prog.progress(i / len(chunks))
        full_transcript = "\n".join(transcripts)

        # 5) Odeslat do Make
        st.success("âœ… Transkripce hotovÃ¡ â€“ odesÃ­lÃ¡m do Makeâ€¦")
        bullets = post_to_make(full_transcript)

        # 6) Zobrazit bulletâ€‘points
        st.session_state.setdefault("bullets", []).extend(bullets)
        render_bullets()

        # 7) Ãšklid
        os.unlink(tmp_input_path)
        shutil.rmtree(tmp_dir, ignore_errors=True)
