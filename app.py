# ai_flipchart_streamlit_whisper_api.py
"""
Streamlit web-app: mikrofon â†’ OpenAI Whisper â†’ ChatGPT â†’ Å¾ivÃ½ Flipchart
---------------------------------------------------------------------------

Novinky
=======
1. AnimovanÃ© vplynutÃ­ (fade-in) bodÅ¯
2. ZÃ¡loÅ¾ky (tabs)
3. DiagnostickÃ½ panel se stavem v sidebaru
"""

from __future__ import annotations

import asyncio
import contextlib
import io
import json
import threading
import wave
from typing import List

import numpy as np
import streamlit as st
from openai import OpenAI
from streamlit_webrtc import WebRtcMode, webrtc_streamer
from streamlit.runtime.scriptrunner import add_script_run_ctx

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("ChybÃ­ OPENAI_API_KEY â€“ pÅ™idejte jej do Secrets / env vars")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)
AUDIO_BATCH_SECONDS = 160

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SESSION STATE INIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "flip_points" not in st.session_state:
    st.session_state.flip_points: List[str] = []
if "transcript_buffer" not in st.session_state:
    st.session_state.transcript_buffer = ""
if "audio_buffer" not in st.session_state:
    st.session_state.audio_buffer: list[bytes] = []
if "status" not in st.session_state:
    st.session_state.status = "ğŸŸ¡ ÄŒekÃ¡m na mikrofonâ€¦"
if "upload_processed" not in st.session_state:
    st.session_state.upload_processed = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STATUS HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def set_status(s: str) -> None:
    """BezpeÄnÄ› zapÃ­Å¡e stav (jen pokud se opravdu zmÄ›nil)."""
    if st.session_state.status != s:
        st.session_state.status = s

@contextlib.contextmanager
def prev_status_ctx(running: str, done: str | None = None):
    """DoÄasnÄ› nastavÃ­ stav, po blokovÃ©m kÃ³du vrÃ¡tÃ­ pÅ¯vodnÃ­."""
    previous = st.session_state.status
    set_status(running)
    try:
        yield
    finally:
        set_status(done or previous)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CSS (fade-in + fullscreen) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STYLES = """
<style>
ul.flipchart {list-style-type:none; padding-left:0;}
ul.flipchart li {opacity:0; transform:translateY(8px); animation:fadeIn 0.45s forwards;}
@keyframes fadeIn {to {opacity:1; transform:translateY(0);}}
.fullscreen header, .fullscreen #MainMenu, .fullscreen footer {visibility:hidden;}
.fullscreen .block-container {padding-top:0.5rem;}
</style>
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_flipchart() -> None:
    st.markdown(STYLES, unsafe_allow_html=True)
    pts = st.session_state.flip_points
    if not pts:
        st.info("ÄŒekÃ¡m na prvnÃ­ shrnutÃ­â€¦")
        return
    st.markdown(
        "<ul class='flipchart'>" +
        "".join(f"<li style='animation-delay:{i*0.1}s'>{p}</li>"
                for i, p in enumerate(pts)) +
        "</ul>",
        unsafe_allow_html=True,
    )

def pcm_frames_to_wav(frames: list[bytes], sample_rate: int = 48000) -> bytes:
    if not frames:
        return b""
    pcm = np.frombuffer(b"".join(frames), dtype=np.int16)
    with io.BytesIO() as buf:
        with wave.open(buf, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sample_rate)
            wf.writeframes(pcm.tobytes())
        buf.seek(0)
        return buf.read()

PROMPT = """
Jsi zkuÅ¡enÃ½ moderÃ¡tor workshopu FWB Summit 2025 â€¦
TvÃ½m Ãºkolem je shrnovat projev do klÃ­ÄovÃ½ch myÅ¡lenek â€¦
"""

def summarise_new_points(text: str, existing: list[str]) -> list[str]:
    msgs = [
        {"role": "system", "content": PROMPT},
        {"role": "user",    "content": text},
        {"role": "assistant", "content": json.dumps(existing, ensure_ascii=False)},
    ]
    raw = client.chat.completions.create(
        model="gpt-3.5-turbo-1106", temperature=0.2, messages=msgs
    ).choices[0].message.content
    try:
        pts = json.loads(raw)
        if not isinstance(pts, list):
            raise ValueError
        return [p.strip() for p in pts if p.strip()]
    except Exception:
        return [ln.lstrip("-â€¢ ").strip() for ln in raw.splitlines() if ln.strip()]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STREAMLIT UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="AI Flipchart", layout="wide")
tabs = st.tabs(["ğŸ›  OvlÃ¡dÃ¡nÃ­", "ğŸ“ Flipchart"])

# ========== TAB 1: OvlÃ¡dÃ¡nÃ­ ==========
with tabs[0]:
    st.header("NastavenÃ­ a vstup zvuku")
    uploaded = st.file_uploader(
        "â–¶ï¸ Nahrajte WAV/MP3 k otestovÃ¡nÃ­ (max pÃ¡r minut)",
        type=["wav", "mp3", "m4a"],
        accept_multiple_files=False,
    )

    # ---------- TESTOVACÃ / UPLOAD VÄšTEV ----------
    if uploaded is not None:
        if not st.session_state.upload_processed:
            with prev_status_ctx("ğŸŸ£ OdesÃ­lÃ¡m soubor do Whisperâ€¦",
                                 done="âœ… Soubor zpracovÃ¡n"):
                st.info("â³ ZpracovÃ¡vÃ¡m nahranÃ½ souborâ€¦")
                transcription = client.audio.transcriptions.create(
                    model="whisper-1", file=uploaded, language="cs"
                ).text
                with prev_status_ctx("ğŸ§  Generuji shrnutÃ­ (soubor)â€¦"):
                    new_pts = summarise_new_points(
                        transcription, st.session_state.flip_points
                    )
                    st.session_state.flip_points.extend(new_pts)
                st.session_state.upload_processed = True
        else:
            st.success("âœ… Soubor uÅ¾ byl zpracovÃ¡n â€“ pÅ™epnÄ›te na zÃ¡loÅ¾ku Flipchart")

    # ---------- LIVE MICROPHONE ----------
    st.subheader("ğŸ¤ Å½ivÃ½ mikrofon")
    webrtc_ctx = webrtc_streamer(
        key="workshop-audio",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"audio": True, "video": False},
    )

    async def pipeline_runner():
        SAMPLE_RATE = 48000
        bytes_per_sec = SAMPLE_RATE * 2
        target = AUDIO_BATCH_SECONDS * bytes_per_sec
        while True:
            if not webrtc_ctx.audio_receiver:
                set_status("ğŸŸ¡ ÄŒekÃ¡m na mikrofonâ€¦")
                await asyncio.sleep(0.1)
                continue

            set_status("ğŸ”´ ZachytÃ¡vÃ¡m audioâ€¦")
            frames = await webrtc_ctx.audio_receiver.get_frames(timeout=1)
            st.session_state.audio_buffer.extend(fr.to_ndarray().tobytes() for fr in frames)

            if sum(len(b) for b in st.session_state.audio_buffer) < target:
                await asyncio.sleep(0.05)
                continue

            wav_bytes = pcm_frames_to_wav(st.session_state.audio_buffer)
            st.session_state.audio_buffer.clear()
            set_status("ğŸŸ£ OdesÃ­lÃ¡m do Whisperâ€¦")
            transcription = client.audio.transcriptions.create(
                model="whisper-1", file=io.BytesIO(wav_bytes), language="cs"
            ).text
            st.session_state.transcript_buffer += " " + transcription

            if len(st.session_state.transcript_buffer.split()) >= 325:
                set_status("ğŸ§  Generuji shrnutÃ­â€¦")
                new_pts = summarise_new_points(
                    st.session_state.transcript_buffer, st.session_state.flip_points
                )
                st.session_state.flip_points.extend(
                    [p for p in new_pts if p not in st.session_state.flip_points]
                )
                st.session_state.transcript_buffer = ""
            set_status("ğŸŸ¢ ÄŒekÃ¡m na dalÅ¡Ã­ dÃ¡vkuâ€¦")
            await asyncio.sleep(0.05)

    if "runner_created" not in st.session_state:
        t = threading.Thread(
            target=lambda: asyncio.run(pipeline_runner()),
            daemon=True, name="audio-runner",
        )
        add_script_run_ctx(t)
        t.start()
        st.session_state.runner_created = True

    # ---------- SIDEBAR ----------
    st.sidebar.header("â„¹ï¸ Stav aplikace")
    st.sidebar.write("Body na flipchartu:", len(st.session_state.flip_points))
    st.sidebar.write("Slov v bufferu:", len(st.session_state.transcript_buffer.split()))
    st.sidebar.subheader("ğŸ§­ Stav zpracovÃ¡nÃ­")
    st.sidebar.write(st.session_state.get("status", "â” NeznÃ¡mÃ½ stav"))

# ========== TAB 2: Flipchart ==========
with tabs[1]:
    st.components.v1.html(
        "<script>document.body.classList.add('fullscreen');</script>", height=0
    )
    render_flipchart()
