# ai_moderator_live.py
"""
AIâ€¯ModerÃ¡tor â€“Â audioâ€¯âœâ€¯bulletâ€‘points
===================================

* **Upload**Â (reÅ¾im 1)Â Â Â â€“ statickÃ½ soubor â†’Â WhisperÂ â†’Â Make â†’Â bulletâ€‘points.
* **Live**Â Â (reÅ¾im 2)Â Â    â€“ stream zÂ mikrofonu / virtuÃ¡lnÃ­ho kabelu pÅ™es WebRTC.
  * Å½ÃDNÃ‰ autorefreshy, Å¾Ã¡dnÃ© `st.rerun()` vÂ smyÄce.
  * Audio se zpracovÃ¡vÃ¡Â **vÂ AudioProcessoru** (API `streamlit_webrtc â‰¥â€¯0.46`).
  * KaÅ¾dÃ½ch `SEGMENT_SEC`Â â†’ WAVÂ â†’Â WhisperÂ â†’Â Make â†’ bulletâ€‘points â®• zapisujeme do
    `st.session_state['bullets']` â†’ UI se pÅ™ekreslÃ­ samo pÅ™i dalÅ¡Ã­m scriptÂ runu.
  * RMS ÃºroveÅˆ se zapisuje do `st.session_state['_rms']` a vykresluje v
    indikÃ¡toru.

TestovÃ¡no lokÃ¡lnÄ› i naÂ StreamlitÂ Cloud (vyÅ¾aduje TURNÂ 443/tcp).
"""
from __future__ import annotations

import asyncio, io, time, wave, logging
from typing import List

import av, numpy as np, streamlit as st, openai, requests
from streamlit_webrtc import (
    webrtc_streamer, WebRtcMode, RTCConfiguration, AudioProcessorBase,
)

# ---------------------------------------------------------------------------
# CONFIG
# ---------------------------------------------------------------------------
SEGMENT_SEC      = 60
WHISPER_MODEL    = "whisper-1"
MAKE_WEBHOOK_URL = st.secrets.get("MAKE_WEBHOOK_URL", "")
OPENAI_API_KEY   = st.secrets.get("OPENAI_API_KEY", "")

client  = openai.OpenAI(api_key=OPENAI_API_KEY)
logger  = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ---------------------------------------------------------------------------
# helpers
# ---------------------------------------------------------------------------

def pcm_to_wav(raw: bytes, sr: int) -> bytes:
    """16â€‘bitÂ mono PCM â†’ WAV (bytes)."""
    buf = io.BytesIO()
    with wave.open(buf, "wb") as w:
        w.setnchannels(1)
        w.setsampwidth(2)
        w.setframerate(sr)
        w.writeframes(raw)
    return buf.getvalue()


def whisper_transcribe(wav: bytes) -> str:
    r = client.audio.transcriptions.create(
        model=WHISPER_MODEL,
        file=("live.wav", io.BytesIO(wav), "audio/wav"),  # type: ignore[arg-type]
    )
    return r.text  # type: ignore[attr-defined]


def post_to_make(txt: str) -> List[str]:
    if not MAKE_WEBHOOK_URL:
        return ["âš ï¸Â MAKE_WEBHOOK_URL chybÃ­ vÂ Secrets"]
    r = requests.post(MAKE_WEBHOOK_URL, json={"transcript": txt}, timeout=30)
    r.raise_for_status()
    return r.json().get("bullets", [])

# ---------------------------------------------------------------------------
# Audio processor â€“Â bÄ›Å¾Ã­ vÂ samostatnÃ©m vlÃ¡knÄ› uvnitÅ™ streamlitâ€‘webrtc
# ---------------------------------------------------------------------------

class LiveAudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.buf: bytearray = bytearray()
        self.last           = time.time()
        self.sr             = 48000

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:  # noqa: N802 â€“ API
        pcm = frame.to_ndarray().tobytes()
        self.buf.extend(pcm)
        self.sr = frame.sample_rate or self.sr

        # RMS â†’ indikÃ¡tor
        rms = float(np.sqrt(np.mean(np.square(np.frombuffer(pcm, np.int16)))) / 32768)
        st.session_state["_rms"] = rms

        # kaÅ¾dÃ½ch SEGMENT_SEC â†’Â zpracovÃ¡nÃ­ segmentu
        if time.time() - self.last >= SEGMENT_SEC and self.buf:
            wav = pcm_to_wav(bytes(self.buf), self.sr)
            self.buf.clear(); self.last = time.time()
            asyncio.get_event_loop().create_task(self.process_segment(wav))
        return frame

    async def process_segment(self, wav: bytes):
        try:
            txt     = await asyncio.to_thread(whisper_transcribe, wav)
            bullets = await asyncio.to_thread(post_to_make, txt)
        except Exception as e:  # network/api
            logger.exception("segment error")
            bullets = [f"âŒÂ {e}"]

        st.session_state.setdefault("bullets", []).extend(bullets)

# ---------------------------------------------------------------------------
# UI
# ---------------------------------------------------------------------------

st.set_page_config("AIÂ ModerÃ¡tor", "ğŸ“", layout="centered")
st.title("ğŸ“Â AI ModerÃ¡tor â€“ audioÂ âœÂ bulletâ€‘points")

st.sidebar.header("NastavenÃ­")
mode = st.sidebar.radio("ReÅ¾im", ["Upload", "Live"], index=1)
SEGMENT_SEC = st.sidebar.slider("Interval segmentu (s)", 15, 180, SEGMENT_SEC, 5)

# ---------------------------------------------------------------------------
# upload mÃ³d â€“Â statickÃ½ soubor
# ---------------------------------------------------------------------------

if mode == "Upload":
    up = st.file_uploader("Nahraj audio", type=["wav", "mp3", "m4a"])
    if up and st.button("Zpracovat"):
        with st.spinner("Whisper â†’ Makeâ€¦"):
            txt     = whisper_transcribe(up.read())
            bullets = post_to_make(txt)
        st.subheader("Bulletâ€‘points")
        st.markdown("\n".join(f"â€¢Â {b}" for b in bullets))

# ---------------------------------------------------------------------------
# live mÃ³d â€“Â WebRTC
# ---------------------------------------------------------------------------

else:
    st.markdown("Klikni **Allow** pro mikrofon / virtuÃ¡lnÃ­ kabel.")

    rtc_cfg: RTCConfiguration = {
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
            {
                "urls": [
                    "turn:global.relay.metered.ca:443?transport=tcp",
                    "turn:global.relay.metered.ca:80?transport=tcp",
                ],
                "username": "global",
                "credential": "global",
            },
        ]
    }

    webrtc_streamer(
        key="live",
        mode=WebRtcMode.SENDONLY,
        rtc_configuration=rtc_cfg,
        media_stream_constraints={"audio": True, "video": False},
        async_processing=True,
        audio_processor_factory=LiveAudioProcessor,
    )

    # --------------------------- vizuÃ¡lnÃ­ indikÃ¡tory ------------------------

    rms  = st.session_state.get("_rms", 0.0)
    bar  = "ğŸŸ©" * int(rms * 20) + "â–«ï¸" * (20 - int(rms * 20))
    st.markdown(f"**ÃšroveÅˆ audia:** {bar}")

    st.subheader("Å½ivÃ© bulletâ€‘points")
    bullets: List[str] = st.session_state.get("bullets", [])
    if bullets:
        st.markdown("\n".join(f"â€¢Â {b}" for b in bullets))
    else:
        st.info("ÄŒekÃ¡m na prvnÃ­ segmentâ€¦")
